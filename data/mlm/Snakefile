from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from Bio import SeqIO, bgzf
import bioframe as bf
import gzip
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import re
from tqdm import tqdm
tqdm.pandas()


species_train = ["Arabidopsis_thaliana.train"]
species_test = ["Arabidopsis_thaliana.test"]


split_chromosomes = {
    "train": [1, 2, 3, 4],
    "test": [5],
}
splits = split_chromosomes.keys()


MIN_CONTIG_LEN = 512
REPEATS_CUT_AWAY_FROM_BORDER = 256-1
FASTA_URL = "http://ftp.ensemblgenomes.org/pub/plants/release-54/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz"
#FASTA_URL = "http://ftp.ensemblgenomes.org/pub/plants/release-54/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa.gz"


rule all:
    input:
        expand("dataset/train/{species}.parquet", species=species_train),
        expand("dataset/test/{species}.512.256.parquet", species=species_test),


rule download_reference:
    output:
        "genome/Arabidopsis_thaliana.raw.fa.gz",
    shell:
        "wget {FASTA_URL} -O {output}"


rule uncompress_reference:
    input:
        "genome/Arabidopsis_thaliana.raw.fa.gz",
    output:
        "genome/Arabidopsis_thaliana.raw.fa",
    shell:
        "gunzip -c {input} > {output}"


rule prepare_mask_intervals:
    input:
        "repeats.bed.gz"
    output:
        "mask_intervals.bed"
    run:
        repeats = pd.read_csv("../../data/mlm/repeats.bed.gz", sep="\t").rename(columns=dict(genoName="chrom", genoStart="start", genoEnd="end"))

        # crucial: filtering step
        print(repeats.shape)
        repeats = repeats[(~repeats.repClass.isin(["Low_complexity", "Simple_repeat"])) & (repeats.milliDiv <= 100)]
        print(repeats.shape)

        repeats = bf.merge(repeats).drop(columns="n_intervals")
        print(repeats.chrom.value_counts())
        repeats.chrom = repeats.chrom.str.replace("Chr", "")
        print(repeats.chrom.value_counts())
        repeats.to_csv(output[0], sep="\t", index=False, header=False)


rule mask_reference:
    input:
        "genome/Arabidopsis_thaliana.raw.fa",
        "mask_intervals.bed"
    output:
        "genome/Arabidopsis_thaliana.fa",
    shell:
        "bedtools maskfasta -soft -fi {input[0]} -bed {input[1]} -fo {output}"


rule compress_reference:
    input:
        "genome/Arabidopsis_thaliana.fa",
    output:
        "genome/Arabidopsis_thaliana.fa.gz",
    shell:
        "gzip -c {input} > {output}"


# only defined nucleotides (ACGTacgt)
rule find_good_intervals:
    input:
        "genome/{species}.fa.gz",
    output:
        "intervals/{species}.tsv.gz",
    shell:
        "python find_good_intervals.py {input} {output} {REPEATS_CUT_AWAY_FROM_BORDER} {MIN_CONTIG_LEN}"


rule split_Ath_intervals:
    input:
        "intervals/Arabidopsis_thaliana.tsv.gz",
    output:
        expand("intervals/Arabidopsis_thaliana.{split}.tsv.gz", split=splits),
    run:
        intervals = pd.read_csv(input[0], sep="\t")
        for split, path in zip(splits, output):
            intervals[intervals.chrom.isin(split_chromosomes[split])].to_csv(path, sep="\t", index=False)

    
rule copy_Ath_genome:
    input:
        "genome/Arabidopsis_thaliana.fa.gz",
    output:
        "genome/Arabidopsis_thaliana.{split}.fa.gz",
    shell:
        "cp {input} {output}"


rule make_train_dataset:
    input:
        "genome/{species}.fa.gz",
        "intervals/{species}.tsv.gz",
    output:
        "dataset/train/{species}.parquet",
    run:
        with gzip.open(input[0], "rt") as handle:
            genome = SeqIO.to_dict(SeqIO.parse(handle, "fasta"))
        df = pd.read_csv(input[1], sep="\t")
        df.chrom = df.chrom.astype(str)
        df["species"] = wildcards["species"]
        print(df)
        df["seq"] = df.apply(lambda row: str(genome[row.chrom][row.start:row.end].seq), axis=1)
        print(df)
        df.to_parquet(output[0], index=False)


rule make_test_dataset:
    input:
        "genome/{species}.fa.gz",
        "intervals/{species}.tsv.gz",
    output:
        "dataset/test/{species}.{window_size}.{step_size}.parquet",
    run:
        with gzip.open(input[0], "rt") as handle:
            genome = SeqIO.to_dict(SeqIO.parse(handle, "fasta"))
        contigs = pd.read_csv(input[1], sep="\t")
        contigs.chrom = contigs.chrom.astype(str)

        window_size = int(wildcards["window_size"])
        step_size = int(wildcards["step_size"])

        def get_contig_windows(contig):
            windows = pd.DataFrame(dict(start=np.arange(contig.start, contig.end-window_size, step_size)))
            windows["end"] = windows.start + window_size
            windows["chrom"] = contig.chrom
            windows["strand"] = "+"
            windows_neg = windows.copy()
            windows_neg.strand = "-"
            windows = pd.concat([windows, windows_neg], ignore_index=True)
            return windows

        windows = pd.concat(contigs.apply(get_contig_windows, axis=1).values, ignore_index=True)
        print(windows)

        def get_window_seq(window):
            seq = genome[window.chrom][window.start:window.end].seq
            if window.strand == "-":
                seq = seq.reverse_complement()
            return str(seq)

        windows["seq"] = windows.progress_apply(get_window_seq, axis=1)
        windows = windows.sample(frac=1.0, random_state=42)
        print(windows)
        windows.to_parquet(output[0])
