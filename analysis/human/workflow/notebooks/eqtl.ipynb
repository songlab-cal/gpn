{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9bf0d43-2e37-46ff-b2a6-3220efde5906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/yss/gbenegas/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import bioframe as bf\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, RocCurveDisplay, average_precision_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3085603a-5559-41f9-aba1-72fee33c6651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from gpn.data import Genome\n",
    "\n",
    "enformer = pd.read_parquet(\"../../results/enformer/merged.parquet\")\n",
    "genome = Genome(\"../../results/genome.fa.gz\")\n",
    "enformer[\"ref_nuc\"] = enformer.progress_apply(lambda v: genome.get_nuc(v.chrom, v.pos).upper(), axis=1)\n",
    "mask = enformer['ref'] != enformer['ref_nuc']\n",
    "enformer.loc[mask, ['ref', 'alt']] = enformer.loc[mask, ['alt', 'ref']].values\n",
    "enformer.to_parquet(\"../../results/enformer/merged.correct_ref_alt.parquet\", index=False)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c667ff-7fa7-476f-909b-5bb6d6682d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: in the future can split train/val and test according to even/odd\n",
    "# and just do 2 splits\n",
    "TRAIN_CHROMS = [str(i) for i in range(1, 11)]\n",
    "VALIDATION_CHROMS = [\"11\", \"12\"]\n",
    "D = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ddbe932-bc67-4eab-92c5-810e9bb967c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>CADD</th>\n",
       "      <th>phyloP-100-vertebrates</th>\n",
       "      <th>phastCons-100-vertebrates</th>\n",
       "      <th>phyloP-241-mammals</th>\n",
       "      <th>GPN-MSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14677</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.370660</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-1.902</td>\n",
       "      <td>-1.095050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17730</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.218470</td>\n",
       "      <td>-2.889</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-4.690</td>\n",
       "      <td>1.481261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>54490</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.201295</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.039775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>63671</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.344458</td>\n",
       "      <td>1.392</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>3.129621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>63697</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.180623</td>\n",
       "      <td>-1.155</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-2.212</td>\n",
       "      <td>-6.382286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58405</th>\n",
       "      <td>X</td>\n",
       "      <td>155744353</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>0.158726</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-0.079454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58406</th>\n",
       "      <td>X</td>\n",
       "      <td>155768650</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.179355</td>\n",
       "      <td>-2.212</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-2.759</td>\n",
       "      <td>7.381042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58407</th>\n",
       "      <td>X</td>\n",
       "      <td>155768714</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.088585</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-3.618934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58408</th>\n",
       "      <td>X</td>\n",
       "      <td>155779999</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>0.076083</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-1.525492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58409</th>\n",
       "      <td>X</td>\n",
       "      <td>155802658</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.466915</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-1.644435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58410 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chrom        pos ref alt  label      CADD  phyloP-100-vertebrates  \\\n",
       "0         1      14677   G   A   True -0.370660                  -0.452   \n",
       "1         1      17730   C   A  False -1.218470                  -2.889   \n",
       "2         1      54490   G   A   True  0.201295                   0.313   \n",
       "3         1      63671   G   A   True -0.344458                   1.392   \n",
       "4         1      63697   T   C   True -1.180623                  -1.155   \n",
       "...     ...        ...  ..  ..    ...       ...                     ...   \n",
       "58405     X  155744353   G   T   True  0.158726                   0.107   \n",
       "58406     X  155768650   G   T   True -1.179355                  -2.212   \n",
       "58407     X  155768714   G   C   True -0.088585                   0.175   \n",
       "58408     X  155779999   A   C  False  0.076083                   0.156   \n",
       "58409     X  155802658   C   G   True -0.466915                  -0.020   \n",
       "\n",
       "       phastCons-100-vertebrates  phyloP-241-mammals   GPN-MSA  \n",
       "0                         -0.000              -1.902 -1.095050  \n",
       "1                         -1.000              -4.690  1.481261  \n",
       "2                         -0.000              -0.029  0.039775  \n",
       "3                         -0.000              -0.253  3.129621  \n",
       "4                         -0.701              -2.212 -6.382286  \n",
       "...                          ...                 ...       ...  \n",
       "58405                     -0.001              -1.722 -0.079454  \n",
       "58406                     -1.000              -2.759  7.381042  \n",
       "58407                     -0.640              -0.502 -3.618934  \n",
       "58408                     -0.000               0.200 -1.525492  \n",
       "58409                     -0.001               0.157 -1.644435  \n",
       "\n",
       "[58410 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    \"CADD.RawScore\",\n",
    "    \"phyloP\",\n",
    "    \"phastCons\",\n",
    "    \"phyloP-Zoonomia\",\n",
    "    \"multiz100way/89/128/64/True/defined.phastCons.percentile-75_0.05_0.001/medium/0.1/42/30000/True/True/True\",\n",
    "]\n",
    "embedding_model = models[-1]\n",
    "\n",
    "model_renaming = {\n",
    "    \"CADD.RawScore\": \"CADD\",\n",
    "    \"multiz100way/89/128/64/True/defined.phastCons.percentile-75_0.05_0.001/medium/0.1/42/30000/True/True/True\": \"GPN-MSA\",\n",
    "    \"phyloP\": \"phyloP-100-vertebrates\",\n",
    "    \"phastCons\": \"phastCons-100-vertebrates\",\n",
    "    \"phyloP-Zoonomia\": \"phyloP-241-mammals\",\n",
    "}\n",
    "\n",
    "V = load_dataset(\"../../results/gtex/merged\", split=\"test\").to_pandas()\n",
    "d = Path(f\"../../results/preds/results/gtex/merged\")\n",
    "\n",
    "for m in models:\n",
    "    model_name = model_renaming.get(m, m)\n",
    "    model_path = d / f\"{m}.parquet\"\n",
    "    V[model_name] = pd.read_parquet(model_path)[\"score\"].values\n",
    "models = [model_renaming.get(m, m) for m in models]\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ef2df5-4315-458d-a1a8-597b238d5ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>CADD</th>\n",
       "      <th>phyloP-100-vertebrates</th>\n",
       "      <th>phastCons-100-vertebrates</th>\n",
       "      <th>phyloP-241-mammals</th>\n",
       "      <th>GPN-MSA</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_758</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14677</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.370660</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-1.902</td>\n",
       "      <td>-1.095050</td>\n",
       "      <td>...</td>\n",
       "      <td>89.838196</td>\n",
       "      <td>199.672211</td>\n",
       "      <td>77.431107</td>\n",
       "      <td>118.214149</td>\n",
       "      <td>76.438446</td>\n",
       "      <td>85.780685</td>\n",
       "      <td>116.801186</td>\n",
       "      <td>134.992523</td>\n",
       "      <td>98.798294</td>\n",
       "      <td>136.315735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17730</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.218470</td>\n",
       "      <td>-2.889</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-4.690</td>\n",
       "      <td>1.481261</td>\n",
       "      <td>...</td>\n",
       "      <td>89.713486</td>\n",
       "      <td>146.122437</td>\n",
       "      <td>71.958832</td>\n",
       "      <td>127.378113</td>\n",
       "      <td>105.690369</td>\n",
       "      <td>146.376953</td>\n",
       "      <td>127.883156</td>\n",
       "      <td>86.037689</td>\n",
       "      <td>110.304382</td>\n",
       "      <td>148.695740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>54490</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.201295</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.039775</td>\n",
       "      <td>...</td>\n",
       "      <td>78.218887</td>\n",
       "      <td>195.490768</td>\n",
       "      <td>65.736748</td>\n",
       "      <td>116.196938</td>\n",
       "      <td>37.669392</td>\n",
       "      <td>61.344448</td>\n",
       "      <td>66.525375</td>\n",
       "      <td>222.361511</td>\n",
       "      <td>86.355278</td>\n",
       "      <td>123.404312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>63671</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.344458</td>\n",
       "      <td>1.392</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>3.129621</td>\n",
       "      <td>...</td>\n",
       "      <td>60.808266</td>\n",
       "      <td>185.885147</td>\n",
       "      <td>56.572441</td>\n",
       "      <td>108.371582</td>\n",
       "      <td>48.275101</td>\n",
       "      <td>132.780823</td>\n",
       "      <td>117.328644</td>\n",
       "      <td>145.440216</td>\n",
       "      <td>78.304321</td>\n",
       "      <td>113.809845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>63697</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.180623</td>\n",
       "      <td>-1.155</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-2.212</td>\n",
       "      <td>-6.382286</td>\n",
       "      <td>...</td>\n",
       "      <td>54.700588</td>\n",
       "      <td>199.266296</td>\n",
       "      <td>62.107849</td>\n",
       "      <td>108.522766</td>\n",
       "      <td>44.507469</td>\n",
       "      <td>128.121628</td>\n",
       "      <td>97.487602</td>\n",
       "      <td>157.041504</td>\n",
       "      <td>88.587296</td>\n",
       "      <td>103.449051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58405</th>\n",
       "      <td>X</td>\n",
       "      <td>155744353</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>0.158726</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-0.079454</td>\n",
       "      <td>...</td>\n",
       "      <td>57.104858</td>\n",
       "      <td>176.774933</td>\n",
       "      <td>72.009583</td>\n",
       "      <td>111.837677</td>\n",
       "      <td>52.309387</td>\n",
       "      <td>86.697060</td>\n",
       "      <td>71.960938</td>\n",
       "      <td>207.810165</td>\n",
       "      <td>105.583748</td>\n",
       "      <td>117.820549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58406</th>\n",
       "      <td>X</td>\n",
       "      <td>155768650</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.179355</td>\n",
       "      <td>-2.212</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-2.759</td>\n",
       "      <td>7.381042</td>\n",
       "      <td>...</td>\n",
       "      <td>108.762115</td>\n",
       "      <td>68.121475</td>\n",
       "      <td>72.987350</td>\n",
       "      <td>104.171677</td>\n",
       "      <td>60.890697</td>\n",
       "      <td>148.558319</td>\n",
       "      <td>88.829399</td>\n",
       "      <td>97.425491</td>\n",
       "      <td>92.073380</td>\n",
       "      <td>120.274269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58407</th>\n",
       "      <td>X</td>\n",
       "      <td>155768714</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.088585</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-3.618934</td>\n",
       "      <td>...</td>\n",
       "      <td>102.985809</td>\n",
       "      <td>61.088684</td>\n",
       "      <td>77.131180</td>\n",
       "      <td>94.744843</td>\n",
       "      <td>62.962914</td>\n",
       "      <td>159.890121</td>\n",
       "      <td>122.761765</td>\n",
       "      <td>98.166855</td>\n",
       "      <td>117.757278</td>\n",
       "      <td>98.256119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58408</th>\n",
       "      <td>X</td>\n",
       "      <td>155779999</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>0.076083</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-1.525492</td>\n",
       "      <td>...</td>\n",
       "      <td>51.425179</td>\n",
       "      <td>167.560028</td>\n",
       "      <td>70.923637</td>\n",
       "      <td>137.495300</td>\n",
       "      <td>67.493050</td>\n",
       "      <td>99.918846</td>\n",
       "      <td>77.596214</td>\n",
       "      <td>244.060669</td>\n",
       "      <td>113.120598</td>\n",
       "      <td>108.227631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58409</th>\n",
       "      <td>X</td>\n",
       "      <td>155802658</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.466915</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-1.644435</td>\n",
       "      <td>...</td>\n",
       "      <td>53.133404</td>\n",
       "      <td>119.811249</td>\n",
       "      <td>42.140701</td>\n",
       "      <td>115.474106</td>\n",
       "      <td>73.199997</td>\n",
       "      <td>81.575409</td>\n",
       "      <td>59.719833</td>\n",
       "      <td>263.933990</td>\n",
       "      <td>152.324432</td>\n",
       "      <td>77.226532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58410 rows × 778 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chrom        pos ref alt  label      CADD  phyloP-100-vertebrates  \\\n",
       "0         1      14677   G   A   True -0.370660                  -0.452   \n",
       "1         1      17730   C   A  False -1.218470                  -2.889   \n",
       "2         1      54490   G   A   True  0.201295                   0.313   \n",
       "3         1      63671   G   A   True -0.344458                   1.392   \n",
       "4         1      63697   T   C   True -1.180623                  -1.155   \n",
       "...     ...        ...  ..  ..    ...       ...                     ...   \n",
       "58405     X  155744353   G   T   True  0.158726                   0.107   \n",
       "58406     X  155768650   G   T   True -1.179355                  -2.212   \n",
       "58407     X  155768714   G   C   True -0.088585                   0.175   \n",
       "58408     X  155779999   A   C  False  0.076083                   0.156   \n",
       "58409     X  155802658   C   G   True -0.466915                  -0.020   \n",
       "\n",
       "       phastCons-100-vertebrates  phyloP-241-mammals   GPN-MSA  ...  \\\n",
       "0                         -0.000              -1.902 -1.095050  ...   \n",
       "1                         -1.000              -4.690  1.481261  ...   \n",
       "2                         -0.000              -0.029  0.039775  ...   \n",
       "3                         -0.000              -0.253  3.129621  ...   \n",
       "4                         -0.701              -2.212 -6.382286  ...   \n",
       "...                          ...                 ...       ...  ...   \n",
       "58405                     -0.001              -1.722 -0.079454  ...   \n",
       "58406                     -1.000              -2.759  7.381042  ...   \n",
       "58407                     -0.640              -0.502 -3.618934  ...   \n",
       "58408                     -0.000               0.200 -1.525492  ...   \n",
       "58409                     -0.001               0.157 -1.644435  ...   \n",
       "\n",
       "       embedding_758  embedding_759  embedding_760  embedding_761  \\\n",
       "0          89.838196     199.672211      77.431107     118.214149   \n",
       "1          89.713486     146.122437      71.958832     127.378113   \n",
       "2          78.218887     195.490768      65.736748     116.196938   \n",
       "3          60.808266     185.885147      56.572441     108.371582   \n",
       "4          54.700588     199.266296      62.107849     108.522766   \n",
       "...              ...            ...            ...            ...   \n",
       "58405      57.104858     176.774933      72.009583     111.837677   \n",
       "58406     108.762115      68.121475      72.987350     104.171677   \n",
       "58407     102.985809      61.088684      77.131180      94.744843   \n",
       "58408      51.425179     167.560028      70.923637     137.495300   \n",
       "58409      53.133404     119.811249      42.140701     115.474106   \n",
       "\n",
       "       embedding_762  embedding_763  embedding_764  embedding_765  \\\n",
       "0          76.438446      85.780685     116.801186     134.992523   \n",
       "1         105.690369     146.376953     127.883156      86.037689   \n",
       "2          37.669392      61.344448      66.525375     222.361511   \n",
       "3          48.275101     132.780823     117.328644     145.440216   \n",
       "4          44.507469     128.121628      97.487602     157.041504   \n",
       "...              ...            ...            ...            ...   \n",
       "58405      52.309387      86.697060      71.960938     207.810165   \n",
       "58406      60.890697     148.558319      88.829399      97.425491   \n",
       "58407      62.962914     159.890121     122.761765      98.166855   \n",
       "58408      67.493050      99.918846      77.596214     244.060669   \n",
       "58409      73.199997      81.575409      59.719833     263.933990   \n",
       "\n",
       "       embedding_766  embedding_767  \n",
       "0          98.798294     136.315735  \n",
       "1         110.304382     148.695740  \n",
       "2          86.355278     123.404312  \n",
       "3          78.304321     113.809845  \n",
       "4          88.587296     103.449051  \n",
       "...              ...            ...  \n",
       "58405     105.583748     117.820549  \n",
       "58406      92.073380     120.274269  \n",
       "58407     117.757278      98.256119  \n",
       "58408     113.120598     108.227631  \n",
       "58409     152.324432      77.226532  \n",
       "\n",
       "[58410 rows x 778 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = pd.concat([\n",
    "    V,\n",
    "    pd.read_parquet(f\"../../results/preds/vep_embedding/results/gtex/merged/{embedding_model}.parquet\")\n",
    "], axis=1)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d06f4a-e0fd-47b1-9fe1-c23d55eaa25f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPN-MSA\n"
     ]
    }
   ],
   "source": [
    "exclude_abs = [\"CADD\", \"phyloP\", \"phyloP-100-vertebrates\", \"phyloP-241-mammals\", \"phyloP-Zoonomia\", 'phastCons-100-vertebrates']\n",
    "for m in models:\n",
    "    if m in V.columns and m not in exclude_abs:\n",
    "        print(m)\n",
    "        V[m] = -V[m].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903a64ff-3904-426f-9a25-b8415fd94b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>CADD</th>\n",
       "      <th>phyloP-100-vertebrates</th>\n",
       "      <th>phastCons-100-vertebrates</th>\n",
       "      <th>phyloP-241-mammals</th>\n",
       "      <th>GPN-MSA</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "      <th>Enformer_l1</th>\n",
       "      <th>Enformer_l2</th>\n",
       "      <th>Enformer_linf</th>\n",
       "      <th>ref_nuc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>54490</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.201295</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.039775</td>\n",
       "      <td>...</td>\n",
       "      <td>37.669392</td>\n",
       "      <td>61.344448</td>\n",
       "      <td>66.525375</td>\n",
       "      <td>222.361511</td>\n",
       "      <td>86.355278</td>\n",
       "      <td>123.404312</td>\n",
       "      <td>-1.388672</td>\n",
       "      <td>-0.039154</td>\n",
       "      <td>-0.008972</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63671</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.344458</td>\n",
       "      <td>1.392</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-3.129621</td>\n",
       "      <td>...</td>\n",
       "      <td>48.275101</td>\n",
       "      <td>132.780823</td>\n",
       "      <td>117.328644</td>\n",
       "      <td>145.440216</td>\n",
       "      <td>78.304321</td>\n",
       "      <td>113.809845</td>\n",
       "      <td>-5.425781</td>\n",
       "      <td>-0.119751</td>\n",
       "      <td>-0.015160</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>108230</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.244932</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.162981</td>\n",
       "      <td>...</td>\n",
       "      <td>59.881935</td>\n",
       "      <td>62.677105</td>\n",
       "      <td>35.060310</td>\n",
       "      <td>262.469727</td>\n",
       "      <td>128.727829</td>\n",
       "      <td>109.150986</td>\n",
       "      <td>-2.343750</td>\n",
       "      <td>-0.045624</td>\n",
       "      <td>-0.005436</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>135203</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.183566</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-0.981487</td>\n",
       "      <td>...</td>\n",
       "      <td>40.877106</td>\n",
       "      <td>85.952293</td>\n",
       "      <td>51.371506</td>\n",
       "      <td>79.543945</td>\n",
       "      <td>43.016586</td>\n",
       "      <td>80.492035</td>\n",
       "      <td>-1.589844</td>\n",
       "      <td>-0.028915</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>263722</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>0.263589</td>\n",
       "      <td>2.308</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-0.079175</td>\n",
       "      <td>...</td>\n",
       "      <td>85.976074</td>\n",
       "      <td>122.279617</td>\n",
       "      <td>222.493393</td>\n",
       "      <td>243.337738</td>\n",
       "      <td>242.634705</td>\n",
       "      <td>86.137978</td>\n",
       "      <td>-6.570312</td>\n",
       "      <td>-0.160400</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54393</th>\n",
       "      <td>9</td>\n",
       "      <td>138175111</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.447451</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>1.593</td>\n",
       "      <td>-3.140078</td>\n",
       "      <td>...</td>\n",
       "      <td>63.530533</td>\n",
       "      <td>140.270294</td>\n",
       "      <td>96.961868</td>\n",
       "      <td>126.968872</td>\n",
       "      <td>82.814278</td>\n",
       "      <td>165.155060</td>\n",
       "      <td>-6.011719</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>-0.029022</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54394</th>\n",
       "      <td>9</td>\n",
       "      <td>138181974</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.365930</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>1.223</td>\n",
       "      <td>-2.610379</td>\n",
       "      <td>...</td>\n",
       "      <td>79.882507</td>\n",
       "      <td>91.263206</td>\n",
       "      <td>320.788513</td>\n",
       "      <td>345.249512</td>\n",
       "      <td>153.408325</td>\n",
       "      <td>70.301895</td>\n",
       "      <td>-2.466797</td>\n",
       "      <td>-0.046692</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54395</th>\n",
       "      <td>9</td>\n",
       "      <td>138198178</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.149840</td>\n",
       "      <td>1.131</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>3.364</td>\n",
       "      <td>-0.731493</td>\n",
       "      <td>...</td>\n",
       "      <td>79.665512</td>\n",
       "      <td>83.797180</td>\n",
       "      <td>303.865906</td>\n",
       "      <td>331.087219</td>\n",
       "      <td>157.133484</td>\n",
       "      <td>69.321274</td>\n",
       "      <td>-3.267578</td>\n",
       "      <td>-0.065796</td>\n",
       "      <td>-0.008209</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54396</th>\n",
       "      <td>9</td>\n",
       "      <td>138210807</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>0.967</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.336</td>\n",
       "      <td>-1.311008</td>\n",
       "      <td>...</td>\n",
       "      <td>59.335842</td>\n",
       "      <td>86.866348</td>\n",
       "      <td>69.095901</td>\n",
       "      <td>237.547241</td>\n",
       "      <td>73.296249</td>\n",
       "      <td>71.876511</td>\n",
       "      <td>-9.937500</td>\n",
       "      <td>-0.290283</td>\n",
       "      <td>-0.111389</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54397</th>\n",
       "      <td>9</td>\n",
       "      <td>138217661</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.168843</td>\n",
       "      <td>0.502</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.643</td>\n",
       "      <td>-0.673834</td>\n",
       "      <td>...</td>\n",
       "      <td>54.724564</td>\n",
       "      <td>50.775078</td>\n",
       "      <td>68.069122</td>\n",
       "      <td>222.024719</td>\n",
       "      <td>50.341022</td>\n",
       "      <td>80.037796</td>\n",
       "      <td>-1.334961</td>\n",
       "      <td>-0.036499</td>\n",
       "      <td>-0.010536</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54398 rows × 782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chrom        pos ref alt  label      CADD  phyloP-100-vertebrates  \\\n",
       "0         1      54490   G   A   True  0.201295                   0.313   \n",
       "1         1      63671   G   A   True -0.344458                   1.392   \n",
       "2         1     108230   C   T   True -0.244932                   0.480   \n",
       "3         1     135203   G   A   True -0.183566                   0.239   \n",
       "4         1     263722   C   G   True  0.263589                   2.308   \n",
       "...     ...        ...  ..  ..    ...       ...                     ...   \n",
       "54393     9  138175111   A   G  False -0.447451                  -0.243   \n",
       "54394     9  138181974   A   C  False -0.365930                  -0.221   \n",
       "54395     9  138198178   A   C  False -0.149840                   1.131   \n",
       "54396     9  138210807   T   A   True  0.009917                   0.967   \n",
       "54397     9  138217661   T   C   True -0.168843                   0.502   \n",
       "\n",
       "       phastCons-100-vertebrates  phyloP-241-mammals   GPN-MSA  ...  \\\n",
       "0                         -0.000              -0.029 -0.039775  ...   \n",
       "1                         -0.000              -0.253 -3.129621  ...   \n",
       "2                         -0.000              -0.118 -0.162981  ...   \n",
       "3                         -0.000               0.338 -0.981487  ...   \n",
       "4                         -0.000              -0.586 -0.079175  ...   \n",
       "...                          ...                 ...       ...  ...   \n",
       "54393                     -0.180               1.593 -3.140078  ...   \n",
       "54394                     -0.117               1.223 -2.610379  ...   \n",
       "54395                     -0.053               3.364 -0.731493  ...   \n",
       "54396                     -0.000               0.336 -1.311008  ...   \n",
       "54397                     -0.001               0.643 -0.673834  ...   \n",
       "\n",
       "       embedding_762  embedding_763  embedding_764  embedding_765  \\\n",
       "0          37.669392      61.344448      66.525375     222.361511   \n",
       "1          48.275101     132.780823     117.328644     145.440216   \n",
       "2          59.881935      62.677105      35.060310     262.469727   \n",
       "3          40.877106      85.952293      51.371506      79.543945   \n",
       "4          85.976074     122.279617     222.493393     243.337738   \n",
       "...              ...            ...            ...            ...   \n",
       "54393      63.530533     140.270294      96.961868     126.968872   \n",
       "54394      79.882507      91.263206     320.788513     345.249512   \n",
       "54395      79.665512      83.797180     303.865906     331.087219   \n",
       "54396      59.335842      86.866348      69.095901     237.547241   \n",
       "54397      54.724564      50.775078      68.069122     222.024719   \n",
       "\n",
       "       embedding_766  embedding_767  Enformer_l1  Enformer_l2  Enformer_linf  \\\n",
       "0          86.355278     123.404312    -1.388672    -0.039154      -0.008972   \n",
       "1          78.304321     113.809845    -5.425781    -0.119751      -0.015160   \n",
       "2         128.727829     109.150986    -2.343750    -0.045624      -0.005436   \n",
       "3          43.016586      80.492035    -1.589844    -0.028915      -0.002449   \n",
       "4         242.634705      86.137978    -6.570312    -0.160400      -0.069763   \n",
       "...              ...            ...          ...          ...            ...   \n",
       "54393      82.814278     165.155060    -6.011719    -0.129883      -0.029022   \n",
       "54394     153.408325      70.301895    -2.466797    -0.046692      -0.006752   \n",
       "54395     157.133484      69.321274    -3.267578    -0.065796      -0.008209   \n",
       "54396      73.296249      71.876511    -9.937500    -0.290283      -0.111389   \n",
       "54397      50.341022      80.037796    -1.334961    -0.036499      -0.010536   \n",
       "\n",
       "       ref_nuc  \n",
       "0            G  \n",
       "1            G  \n",
       "2            C  \n",
       "3            G  \n",
       "4            C  \n",
       "...        ...  \n",
       "54393        A  \n",
       "54394        A  \n",
       "54395        A  \n",
       "54396        T  \n",
       "54397        T  \n",
       "\n",
       "[54398 rows x 782 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enformer = pd.read_parquet(\"../../results/enformer/merged.correct_ref_alt.parquet\")\n",
    "cols = [\"chrom\", \"pos\", \"ref\", \"alt\"]\n",
    "V = V.merge(enformer, on=cols, how=\"inner\")\n",
    "models += [\n",
    "    \"Enformer_l2\",\n",
    "    #\"Enformer_l1\",\n",
    "    #\"Enformer_linf\",\n",
    "]\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a80b04-fb6d-4d6a-8a1b-45c950a8de4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27804, 2485, 24109)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_train = V[V.chrom.isin(TRAIN_CHROMS)].copy()\n",
    "V_validation = V[V.chrom.isin(VALIDATION_CHROMS)].copy()\n",
    "V_test = V[(~V.chrom.isin(TRAIN_CHROMS)) & (~V.chrom.isin(VALIDATION_CHROMS))].copy()\n",
    "len(V_train), len(V_validation), len(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffcb68c1-1ad7-4985-985e-e749decf1566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 768/768 [00:04<00:00, 186.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>embedding_112</td>\n",
       "      <td>0.486988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>embedding_761</td>\n",
       "      <td>0.485115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>embedding_501</td>\n",
       "      <td>0.481255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>embedding_39</td>\n",
       "      <td>0.481202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>embedding_457</td>\n",
       "      <td>0.474064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>embedding_402</td>\n",
       "      <td>0.227796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>embedding_608</td>\n",
       "      <td>0.226087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>embedding_381</td>\n",
       "      <td>0.225017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>embedding_173</td>\n",
       "      <td>0.224792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>embedding_14</td>\n",
       "      <td>0.223814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model     AUPRC\n",
       "112  embedding_112  0.486988\n",
       "761  embedding_761  0.485115\n",
       "501  embedding_501  0.481255\n",
       "39    embedding_39  0.481202\n",
       "457  embedding_457  0.474064\n",
       "..             ...       ...\n",
       "402  embedding_402  0.227796\n",
       "608  embedding_608  0.226087\n",
       "381  embedding_381  0.225017\n",
       "173  embedding_173  0.224792\n",
       "14    embedding_14  0.223814\n",
       "\n",
       "[768 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train = pd.DataFrame([\n",
    "    [f\"embedding_{i}\", average_precision_score(V_train.label, -V_train[f\"embedding_{i}\"])]\n",
    "    for i in tqdm(range(D))\n",
    "], columns=[\"Model\", \"AUPRC\"]).sort_values(\"AUPRC\", ascending=False)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06af82d7-2684-462f-bfd4-a573030d959e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['embedding_112', 'embedding_761', 'embedding_501', 'embedding_39',\n",
       "       'embedding_457', 'embedding_243', 'embedding_661', 'embedding_276',\n",
       "       'embedding_132', 'embedding_481'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices = results_train.Model.values\n",
    "sorted_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a88d8d79-c08e-4b35-a745-e07be8459a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "V_test[\"inner_product_select_dimensions\"] = V_test[sorted_indices[:10]].sum(axis=1)\n",
    "models.append(\"inner_product_select_dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "336d111c-1206-4dad-bae2-d983a13684af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 83.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CADD</td>\n",
       "      <td>0.552221</td>\n",
       "      <td>0.392787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phyloP-100-vertebrates</td>\n",
       "      <td>0.525723</td>\n",
       "      <td>0.347827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phastCons-100-vertebrates</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.330502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phyloP-241-mammals</td>\n",
       "      <td>0.530219</td>\n",
       "      <td>0.368644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPN-MSA</td>\n",
       "      <td>0.548426</td>\n",
       "      <td>0.373345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enformer_l2</td>\n",
       "      <td>0.689309</td>\n",
       "      <td>0.560447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inner_product_select_dimensions</td>\n",
       "      <td>0.666616</td>\n",
       "      <td>0.499504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model     AUROC     AUPRC\n",
       "0                             CADD  0.552221  0.392787\n",
       "1           phyloP-100-vertebrates  0.525723  0.347827\n",
       "2        phastCons-100-vertebrates  0.474219  0.330502\n",
       "3               phyloP-241-mammals  0.530219  0.368644\n",
       "4                          GPN-MSA  0.548426  0.373345\n",
       "5                      Enformer_l2  0.689309  0.560447\n",
       "6  inner_product_select_dimensions  0.666616  0.499504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subtitle(n_pathogenic, n_benign):\n",
    "    return f\"n={n_pathogenic} vs. {n_benign}\"\n",
    "\n",
    "pos_prop = []\n",
    "\n",
    "rows = []\n",
    "V_c = V_test.dropna(subset=models)\n",
    "n_pos, n_neg = (V_c.label==True).sum(), (V_c.label==False).sum()\n",
    "subtitle = get_subtitle(n_pos, n_neg)\n",
    "pos_prop.append(n_pos/(n_pos+n_neg))\n",
    "\n",
    "for m in tqdm(models):\n",
    "    AUROC = roc_auc_score(V_c.label==True, -V_c[m])\n",
    "    AUPRC = average_precision_score(V_c.label==True, -V_c[m])\n",
    "    rows.append([m, AUROC, AUPRC])\n",
    "results = pd.DataFrame(rows, columns=[\"Model\", \"AUROC\", \"AUPRC\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0a1e7b-cc56-4cdf-a858-e096782f76a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,1.5))\n",
    "sns.pointplot(\n",
    "    data=results.sort_values(\"AUPRC\", ascending=False).replace(\"Enformer_l2\", \"Enformer\"),\n",
    "    y=\"Model\",\n",
    "    x=\"AUPRC\",\n",
    "    join=False,\n",
    ")\n",
    "plt.title(subtitle);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb00d3-330a-4035-8aa9-9a6134e7b980",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Training a layer on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c213a2bb-3d84-4d0a-88be-55fdca59899a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: try without freezing!\n",
    "# TODO: start with fwd strand only (at test time), then average both\n",
    "# TODO: make sure this works for both GPN and GPN-MSA\n",
    "# TODO: potentially add loss weight = inverse square prop or similar (accepted by BCEWithLogitsLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4c135bb-a5bd-41d1-beec-c9af20567dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss, BCEWithLogitsLoss\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    PretrainedConfig,\n",
    "    PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutput,\n",
    "    MaskedLMOutput,\n",
    "    SequenceClassifierOutput,\n",
    ")\n",
    "from gpn.data import Tokenizer, ReverseComplementer\n",
    "from gpn.model import GPNRoFormerPreTrainedModel, GPNRoFormerModel\n",
    "\n",
    "\"\"\"\n",
    "class GPNRoformerForAffectTrait(GPNRoFormerPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = GPNRoFormerModel(config)\n",
    "        self.linear1 = nn.Linear(config.hidden_size, config.affect_trait_dim)\n",
    "        self.linear2 = nn.Linear(1, 1)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "        \n",
    "    def embed_seq(self, input_ids=None, aux_features=None):\n",
    "        x = self.model(input_ids=input_ids, aux_features=aux_features).last_hidden_state\n",
    "        return self.linear1(x)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids_ref=None, aux_features_ref=None,\n",
    "        input_ids_alt=None, aux_features_alt=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        embedding_ref = self.embed_seq(\n",
    "            input_ids=input_ids_ref, aux_features=aux_features_ref,\n",
    "        )\n",
    "        embedding_alt = self.embed_seq(\n",
    "            input_ids=input_ids_alt, aux_features=aux_features_alt,\n",
    "        )\n",
    "        minus_dot_product = -(embedding_ref * embedding_alt).sum(dim=(1,2)).unsqueeze(1)\n",
    "        logits = self.linear2(minus_dot_product).squeeze()\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        nn.init.normal_(self.weights, mean=np.log(1/in_featuresZ), std=0.02)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights_normalized = torch.exp(self.weights)\n",
    "        print(f\"{weights_normalized=}\")\n",
    "        return F.linear(x, weights_normalized, self.bias)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GPNRoformerForAffectTrait(GPNRoFormerPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = GPNRoFormerModel(config)\n",
    "        self.linear = nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "        \n",
    "    def embed_seq(self, input_ids=None, aux_features=None):\n",
    "        return self.model(input_ids=input_ids, aux_features=aux_features).last_hidden_state\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids_ref=None, aux_features_ref=None,\n",
    "        input_ids_alt=None, aux_features_alt=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        embedding_ref = self.embed_seq(\n",
    "            input_ids=input_ids_ref, aux_features=aux_features_ref,\n",
    "        )\n",
    "        embedding_alt = self.embed_seq(\n",
    "            input_ids=input_ids_alt, aux_features=aux_features_alt,\n",
    "        )\n",
    "        # TODO: should enforce positivity by using F.linear or something\n",
    "        minus_dot_product = -(embedding_ref * embedding_alt).sum(dim=1)\n",
    "        print(f\"{minus_dot_product=}\")\n",
    "        print(f\"{minus_dot_product.shape=}\")\n",
    "        logits = self.linear(minus_dot_product).squeeze()\n",
    "        print(f\"{logits=}\")\n",
    "        print(f\"{logits.shape=}\")\n",
    "        raise Exception(\"debug\")\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "        )\n",
    "\n",
    "\n",
    "class DataProvider(object):\n",
    "    def __init__(self, genome_msa, window_size):\n",
    "        self.genome_msa = genome_msa\n",
    "        self.window_size = window_size\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.reverse_complementer = ReverseComplementer()\n",
    "\n",
    "    def tokenize_function(self, V):\n",
    "        # we convert from 1-based coordinate (standard in VCF) to\n",
    "        # 0-based, to use with GenomeMSA\n",
    "        #print(V)\n",
    "        #raise Exception(\"debug\")\n",
    "        chrom = np.array(V[\"chrom\"])\n",
    "        pos = np.array(V[\"pos\"]) - 1\n",
    "        start = pos - self.window_size // 2\n",
    "        end = pos + self.window_size // 2\n",
    "        \n",
    "        msa_fwd, msa_rev = self.genome_msa.get_msa_batch_fwd_rev(\n",
    "            chrom,\n",
    "            start,\n",
    "            end,\n",
    "            tokenize=True,\n",
    "        )\n",
    "        pos_fwd = self.window_size // 2\n",
    "        pos_rev = pos_fwd - 1 if self.window_size % 2 == 0 else pos_fwd\n",
    "\n",
    "        ref_fwd = np.array(\n",
    "            [np.frombuffer(x.encode(\"ascii\"), dtype=\"S1\") for x in V[\"ref\"]]\n",
    "        )\n",
    "        alt_fwd = np.array(\n",
    "            [np.frombuffer(x.encode(\"ascii\"), dtype=\"S1\") for x in V[\"alt\"]]\n",
    "        )\n",
    "        ref_rev = self.reverse_complementer(ref_fwd)\n",
    "        alt_rev = self.reverse_complementer(alt_fwd)\n",
    "\n",
    "        def prepare_output(msa, pos, ref, alt):\n",
    "            ref, alt = self.tokenizer(ref.flatten()), self.tokenizer(alt.flatten())\n",
    "            input_ids, aux_features = msa[:, :, 0], msa[:, :, 1:]\n",
    "            assert (\n",
    "                input_ids[:, pos] == ref\n",
    "            ).all(), f\"{input_ids[:, pos].tolist()}, {ref.tolist()}\"\n",
    "            input_ids_alt = input_ids.copy()\n",
    "            input_ids_alt[:, pos] = alt\n",
    "            input_ids = input_ids.astype(np.int64)\n",
    "            input_ids_alt = input_ids_alt.astype(np.int64)\n",
    "            return input_ids, aux_features, input_ids_alt, aux_features\n",
    "\n",
    "        res = {}\n",
    "        #(\n",
    "        #    res[\"input_ids_ref_fwd\"],\n",
    "        #    res[\"aux_features_ref_fwd\"],\n",
    "        #    res[\"input_ids_alt_fwd\"],\n",
    "        #    res[\"aux_features_alt_fwd\"],\n",
    "        #) = prepare_output(msa_fwd, pos_fwd, ref_fwd, alt_fwd)\n",
    "        #(\n",
    "        #    res[\"input_ids_ref_rev\"],\n",
    "        #    res[\"aux_features_ref_rev\"],\n",
    "        #    res[\"input_ids_alt_rev\"],\n",
    "        #    res[\"aux_features_alt_rev\"],\n",
    "        #) = prepare_output(msa_rev, pos_rev, ref_rev, alt_rev)\n",
    "        \n",
    "        (\n",
    "            res[\"input_ids_ref\"],\n",
    "            res[\"aux_features_ref\"],\n",
    "            res[\"input_ids_alt\"],\n",
    "            res[\"aux_features_alt\"],\n",
    "        ) = prepare_output(msa_fwd, pos_fwd, ref_fwd, alt_fwd)\n",
    "        if \"label\" in V:\n",
    "            res[\"labels\"] = V[\"label\"]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "290b259a-2be2-4331-95ad-9d0d529625fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MSA...\n",
      "Loading MSA... Done\n"
     ]
    }
   ],
   "source": [
    "from gpn.data import GenomeMSA\n",
    "\n",
    "genome_msa = GenomeMSA(\"../../results/msa/multiz100way/89/all.zarr\")\n",
    "data_provider = DataProvider(genome_msa, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "caf38c35-8344-4239-b401-dfa477865549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def my_load_dataset(V):\n",
    "    dataset = V[cols + [\"label\"]].copy()\n",
    "    dataset.label = dataset.label.astype(float)\n",
    "    dataset = Dataset.from_pandas(dataset)\n",
    "    dataset.set_transform(data_provider.tokenize_function)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1cdb79d9-5d84-4644-8d06-e734dc56853e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_test():\n",
    "    seed = 42\n",
    "    set_seed(seed)\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\"songlab/gpn-msa-sapiens\")\n",
    "    #config.affect_trait_dim = 64\n",
    "    model = GPNRoformerForAffectTrait.from_pretrained(\"songlab/gpn-msa-sapiens\", config=config)\n",
    "    for param in model.model.parameters(): param.requires_grad = False  # freeze the encoder\n",
    "\n",
    "    train_dataset = my_load_dataset(V_train).shuffle(seed=42)\n",
    "    validation_dataset = my_load_dataset(V_validation)\n",
    "    test_dataset = my_load_dataset(V_test)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=tempfile.TemporaryDirectory().name,\n",
    "        per_device_train_batch_size=256,\n",
    "        per_device_eval_batch_size=4096,\n",
    "        gradient_accumulation_steps=1,\n",
    "        dataloader_num_workers=8,\n",
    "        fp16=True,\n",
    "        weight_decay=0.01,\n",
    "        optim=\"adamw_torch\",\n",
    "        seed=seed,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        num_train_epochs=10,\n",
    "        warmup_ratio=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        learning_rate=1e-4,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=validation_dataset,\n",
    "    )\n",
    "    # could try wandb sweep for hparams (random search)\n",
    "    trainer.train()\n",
    "    test_output = trainer.predict(test_dataset=test_dataset).predictions\n",
    "    return test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c0bb90b-994f-425c-8412-8ee217bca08b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPNRoformerForAffectTrait were not initialized from the model checkpoint at songlab/gpn-msa-sapiens and are newly initialized: ['linear.weight', 'linear.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minus_dot_product=tensor([[ -60.6983, -254.6215, -394.4081,  ..., -202.8857, -138.6718,\n",
      "          -87.7185],\n",
      "        [ -49.5687, -142.1396, -357.7785,  ..., -261.0012,  -75.3636,\n",
      "         -125.9182],\n",
      "        [-276.4459, -208.6881, -310.6472,  ..., -204.5766, -171.9836,\n",
      "          -63.6281],\n",
      "        ...,\n",
      "        [ -41.0637,  -74.5628, -334.7136,  ..., -285.5878, -107.0852,\n",
      "         -133.8367],\n",
      "        [-246.7644, -145.7773, -307.3300,  ..., -239.6556,  -62.3692,\n",
      "          -67.5684],\n",
      "        [ -56.8814,  -68.4629, -282.0012,  ..., -211.7873,  -72.5903,\n",
      "         -155.8084]], device='cuda:0')\n",
      "minus_dot_product.shape=torch.Size([256, 768])\n",
      "logits=tensor([-12.5859,  -4.9531,  56.3750, -24.1094,   0.6616,  -1.5615, -10.8125,\n",
      "         63.0312, -26.8125, -31.0000, -49.5938, -29.1875, -30.9062, -30.7656,\n",
      "        -20.0625, -12.8047, -24.1250, -19.0469, -25.4219,  56.8750, -20.7812,\n",
      "        -25.5000,   3.6465, -24.8594,  -5.6758, -27.5156, -17.2031, -31.4844,\n",
      "        -16.8750, -28.0938,  -8.5703,  -8.5625, -13.7969,  50.0938,  15.0469,\n",
      "        -26.8281, -20.7969,  33.7188,   2.3594, -23.6875, -16.7031,  -5.5000,\n",
      "        -22.5000,  -7.8477,  -9.1875, -30.7031, -14.3359,  44.9375,  -4.6133,\n",
      "        -17.6719,  -7.2891,  -2.6484,  13.4922, -34.6250,   7.2227, -14.1016,\n",
      "         -5.2617, -12.5781,  -3.5957, -30.6250,  14.2109,  -3.4160,  -8.4922,\n",
      "        -22.7969, -31.5781, -18.4688,  17.2969, -35.1250, -24.3906, -33.8750,\n",
      "        -16.7656, -23.0938,  -5.8125,   8.6406, -29.0625, -20.2656, -16.1406,\n",
      "        -28.1406,  36.5312, -12.7500,  -6.4609,   2.9512, -42.5312,  13.2344,\n",
      "          9.9531,  46.4062, -39.4688,  36.5938,  -7.3828,  45.7812,  -4.1953,\n",
      "         48.6875, -29.5000, -17.8906, -35.9688,  24.7031,  -8.0703,  -0.3179,\n",
      "         15.5469, -28.6875, -16.9375,  39.7500, -22.9844,  55.5000, -20.4375,\n",
      "        -19.7969, -43.4062, -24.8438, -28.7031, -26.0000, -12.2500, -12.4609,\n",
      "         43.0625,  21.9531,  51.4375, -22.1250,  -0.7012, -25.8438, -30.9062,\n",
      "        -22.5156,  59.5000,  -4.2422, -12.2188, -27.7969, -16.6250,  44.5000,\n",
      "         -5.0039,  22.2188, -28.7500, -40.0938, -58.3750,  -0.4399,  11.8203,\n",
      "          3.2500,  50.8750,  33.6875,  -2.7871,  -6.8086,  10.4609, -20.0781,\n",
      "         42.6875, -15.9688,  17.9219, -25.9844, -26.1719,  11.9219, -11.4844,\n",
      "         32.2500, -13.2422, -31.3594,   5.0195,  42.7812, -24.1094, -46.6875,\n",
      "         46.0000, -21.9375,  33.5625, -17.6875,  49.0000, -34.0000,  32.9375,\n",
      "        -19.8906, -16.5000,   0.3452, -28.3750, -29.2812, -16.8750, -26.8594,\n",
      "        -39.0000,  -2.3613, -21.8125,   2.1738, -13.6953, -21.0938, -49.1875,\n",
      "        -31.7656, -56.5938, -14.8906,  -8.2109, -14.7578,  61.6250,  -0.3337,\n",
      "        -25.4688, -39.5312, -24.6406, -38.8750, -25.3594, -16.6094,   8.6172,\n",
      "        -15.1484,  43.3125,  40.2812,  20.3125, -14.3750, -44.6562, -23.4375,\n",
      "        -16.2656, -38.3438, -33.7500, -13.3906, -20.4062,   1.3359, -17.8125,\n",
      "        -23.2969,  -8.4766,  -6.4922,  25.1094,  48.9062, -31.8750,  -5.4258,\n",
      "        -39.0312, -13.3828,   2.9707,  19.3750,  15.0625,   3.3652, -42.8750,\n",
      "        -35.5000,  41.5000,  41.1562, -15.3281,  34.4375, -20.6250,  52.6562,\n",
      "        -13.4688,  -8.1328, -11.8281, -18.3594, -12.4609, -37.3750, -30.3906,\n",
      "        -12.3438, -10.8203, -25.0781,  -0.6768, -26.0938,  -1.8262,  18.8438,\n",
      "         33.1875, -34.0000,   3.9727,  11.3594, -26.8438, -15.3984,  -8.3281,\n",
      "        -26.4375,  -5.3711, -25.5000,  62.0000,  -8.5547, -15.6016,  55.7812,\n",
      "        -33.1875, -14.2578,  27.5469, -43.5625], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SqueezeBackward0>)\n",
      "logits.shape=torch.Size([256])\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "debug",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m V_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_on_top\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtrain_and_test()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_on_top\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m models: models\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_on_top\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[86], line 43\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     37\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     38\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     39\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     40\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mvalidation_dataset,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# could try wandb sweep for hparams (random search)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     44\u001b[0m test_output \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(test_dataset\u001b[38;5;241m=\u001b[39mtest_dataset)\u001b[38;5;241m.\u001b[39mpredictions\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_output\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1592\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1593\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1594\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1595\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1596\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1892\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2776\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2776\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   2778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2779\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2801\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2800\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2801\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/gbenegas/software/mambaforge/envs/gpn/lib/python3.11/site-packages/accelerate/utils/operations.py:659\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/users/gbenegas/software/mambaforge/envs/gpn/lib/python3.11/site-packages/accelerate/utils/operations.py:647\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[83], line 114\u001b[0m, in \u001b[0;36mGPNRoformerForAffectTrait.forward\u001b[0;34m(self, input_ids_ref, aux_features_ref, input_ids_alt, aux_features_alt, labels)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mException\u001b[0m: debug"
     ]
    }
   ],
   "source": [
    "V_test[\"layer_on_top\"] = -train_and_test()\n",
    "if \"layer_on_top\" not in models: models.append(\"layer_on_top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2072356-f068-4136-87a9-5514ede607a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "features = [f\"embedding_{i}\" for i in range(D)]\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear', LogisticRegressionCV(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        scoring=\"average_precision\",\n",
    "        #Cs=np.logspace(-5, -3, 10),\n",
    "        n_jobs=8,\n",
    "        max_iter=1000,\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf.fit(V_train[features], V_train.label)\n",
    "pred = -clf.predict_proba(V_test[features])[:, 1]\n",
    "V_test[\"inner_product_logistic_regression\"] = pred\n",
    "if \"inner_product_logistic_regression\" not in models: models.append(\"inner_product_logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1943b61-2b54-4d8c-9442-61d8e8dd0150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 85.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CADD</td>\n",
       "      <td>0.552221</td>\n",
       "      <td>0.392787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phyloP-100-vertebrates</td>\n",
       "      <td>0.525723</td>\n",
       "      <td>0.347827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phastCons-100-vertebrates</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.330502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phyloP-241-mammals</td>\n",
       "      <td>0.530219</td>\n",
       "      <td>0.368644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPN-MSA</td>\n",
       "      <td>0.548426</td>\n",
       "      <td>0.373345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enformer_l2</td>\n",
       "      <td>0.689309</td>\n",
       "      <td>0.560447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inner_product_select_dimensions</td>\n",
       "      <td>0.666616</td>\n",
       "      <td>0.499504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>layer_on_top</td>\n",
       "      <td>0.583344</td>\n",
       "      <td>0.400157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inner_product_logistic_regression</td>\n",
       "      <td>0.684591</td>\n",
       "      <td>0.514682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model     AUROC     AUPRC\n",
       "0                               CADD  0.552221  0.392787\n",
       "1             phyloP-100-vertebrates  0.525723  0.347827\n",
       "2          phastCons-100-vertebrates  0.474219  0.330502\n",
       "3                 phyloP-241-mammals  0.530219  0.368644\n",
       "4                            GPN-MSA  0.548426  0.373345\n",
       "5                        Enformer_l2  0.689309  0.560447\n",
       "6    inner_product_select_dimensions  0.666616  0.499504\n",
       "7                       layer_on_top  0.583344  0.400157\n",
       "8  inner_product_logistic_regression  0.684591  0.514682"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subtitle(n_pathogenic, n_benign):\n",
    "    return f\"n={n_pathogenic} vs. {n_benign}\"\n",
    "\n",
    "pos_prop = []\n",
    "\n",
    "rows = []\n",
    "V_c = V_test.dropna(subset=models)\n",
    "n_pos, n_neg = (V_c.label==True).sum(), (V_c.label==False).sum()\n",
    "subtitle = get_subtitle(n_pos, n_neg)\n",
    "pos_prop.append(n_pos/(n_pos+n_neg))\n",
    "\n",
    "for m in tqdm(models):\n",
    "    AUROC = roc_auc_score(V_c.label==True, -V_c[m])\n",
    "    AUPRC = average_precision_score(V_c.label==True, -V_c[m])\n",
    "    rows.append([m, AUROC, AUPRC])\n",
    "results = pd.DataFrame(rows, columns=[\"Model\", \"AUROC\", \"AUPRC\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "212bc235-0e70-464a-9a38-ea35605e666d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,1.5))\n",
    "sns.pointplot(\n",
    "    data=results.sort_values(\"AUPRC\", ascending=False).replace(\"Enformer_l2\", \"Enformer\"),\n",
    "    y=\"Model\",\n",
    "    x=\"AUPRC\",\n",
    "    join=False,\n",
    ")\n",
    "plt.title(subtitle);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dace4b-5b29-456a-9b40-52d7341f80e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpn",
   "language": "python",
   "name": "gpn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
