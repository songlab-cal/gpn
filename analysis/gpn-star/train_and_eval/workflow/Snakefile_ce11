from Bio import SeqIO
from Bio.Seq import Seq
import bioframe as bf
from datasets import load_dataset, disable_caching, Dataset
from gpn.star.data import load_fasta, load_table, Genome, load_dataset_from_file_or_dir
from gpn.star.data import (
    filter_defined,
    filter_length,
    load_table,
    add_flank,
    get_annotation_features,
    add_jitter,
    get_promoters,
    get_random_intervals,
    union_intervals,
    intersect_intervals,
    intervals_size,
    get_balanced_intervals,
)
from gpn.star.data import make_windows, get_seq
from gpn.star.data import GenomeMSA
from gpn.star.utils import normalize_logits, get_entropy
import gzip
from joblib import Parallel, delayed
import numpy as np
import os
import pandas as pd
from pathlib import Path
import scipy.sparse as sp_sparse
from scipy.special import softmax
from scipy.stats import combine_pvalues, entropy
from tqdm import tqdm

tqdm.pandas()

NUCLEOTIDES = list("ACGT")
WINDOW_SIZE = 128
FASTA_URLS = {
    "ce11": "http://ftp.ensembl.org/pub/release-107/fasta/caenorhabditis_elegans/dna/Caenorhabditis_elegans.WBcel235.dna_sm.toplevel.fa.gz"
}

CALIBRATION_CONFIGS = {
    "use_ancestral_repeats": False,
    "target_repeats": None,
    "outgroup_repeats": None,
    "chain_file": None,
    "phylop": "phyloP135way",
    "phastcons": "phastCons135way",
}

SEX_CHROMS = ["X"]

SPLIT_CHROMS = {
    "train": ["II", "IV", "V"] + SEX_CHROMS,
    "validation": ["I"],
    "test": ["III"],
}
SPLITS = SPLIT_CHROMS.keys()

CHROMS = np.concatenate(list(SPLIT_CHROMS.values()))

AUTOSOMES = ["I", "II", "III", "IV", "V"]

PHYLOP_PHASTCONS_GROUP = {"phastCons135way": "phyloP135way"}

vep_datasets = [
    "results/celegans_snps/rare_vs_common",
    "results/celegans_lethal/filtered",
]

model_template = "{genome}/{time_enc}/{clade_thres}/{dataset}/{model_size}/{loss_weight}/{seed}/{max_steps}/{use_aux_features}/{weight_conserved}/{flip_nonconserved}"

# default is first
hparams = {
    "dataset": [
        "multiz135way/135/128/64/True/defined.phastCons135way.percentile-75_0.05_0.001",
    ],
    "interval": [
        "128/64/True/defined.phastCons135way.percentile-75_0.05_0.001",
    ],
    "genome": [
        "ce11",
    ],
    "time_enc": [
        "fire_1",
    ],
    "clade_thres": [
        "0.2",
    ],
    "use_aux_features": [
        True,
    ],
    "loss_weight": [
        0.1,
    ],
    "weight_conserved": [
        True,
    ],
    "flip_nonconserved": [
        0.1,
    ],
}

default_d = {k: v[0] for k, v in hparams.items()}
hparam_models = [expand(model_template, **default_d, allow_missing=True)[0]]

# one ablation at a time
for k, v in hparams.items():
    for vv in v[1:]:
        new_d = default_d.copy()
        new_d[k] = vv
        hparam_models.append(expand(model_template, **new_d, allow_missing=True)[0])

models = sum(
    [
        expand(
            m,
            seed=[
                42,
            ],
            max_steps=[
                50_000,
            ],
            model_size=[
                "small",
                "medium",
            ],
        )
        for m in hparam_models
    ],
    [],
)
best_model = models[0]
# models = [best_model]


include: "rules/common.smk"
include: "rules/training.smk"
include: "rules/vep.smk"
include: "rules/logits.smk"
include: "rules/calibration.smk"
# include: "rules/embeddings.smk"
include: "rules/conservation.smk"


# models += ['ce11/phastCons135way', 'ce11/phyloP135way']

print(models)
print(vep_datasets)


rule all:
    input:
        #expand("results/checkpoints/{model}", model=models),
        expand(
            "results/preds/llr/{dataset}/{model}.parquet",
            model=models,
            dataset=vep_datasets,
        ),
