from Bio import SeqIO
from Bio.Seq import Seq
import bioframe as bf
from datasets import load_dataset, disable_caching, Dataset
from gpn.star.data import load_fasta, load_table, Genome, load_dataset_from_file_or_dir
from gpn.star.data import (
    filter_defined, filter_length, load_table, add_flank, get_annotation_features,
    add_jitter, get_promoters, get_random_intervals, union_intervals,
    intersect_intervals, intervals_size, get_balanced_intervals,
)
from gpn.star.data import make_windows, get_seq
from gpn.star.data import GenomeMSA
from gpn.star.utils import normalize_logits, get_entropy
import gzip
from joblib import Parallel, delayed
import numpy as np
import os
import pandas as pd
from pathlib import Path
import scipy.sparse as sp_sparse
from scipy.special import softmax
from scipy.stats import combine_pvalues, entropy
from tqdm import tqdm
tqdm.pandas()

NUCLEOTIDES = list("ACGT")
WINDOW_SIZE = 128
FASTA_URLS = {"ce11": "http://ftp.ensembl.org/pub/release-107/fasta/caenorhabditis_elegans/dna/Caenorhabditis_elegans.WBcel235.dna_sm.toplevel.fa.gz"}

CALIBRATION_CONFIGS = {
    "use_ancestral_repeats": False,
    "target_repeats": None,
    "outgroup_repeats": None,
    "chain_file": None,
    "phylop": "phyloP135way",
    "phastcons": "phastCons135way",
}

SEX_CHROMS = ['X']

SPLIT_CHROMS = {
    "train": ['II', 'IV', 'V'] + SEX_CHROMS,
    "validation": ["I"],
    "test": ["III"],
}
SPLITS = SPLIT_CHROMS.keys()

CHROMS = np.concatenate(list(SPLIT_CHROMS.values()))

AUTOSOMES = ['I', 'II', 'III', 'IV', 'V']

PHYLOP_PHASTCONS_GROUP = {'phastCons135way': 'phyloP135way'}

vep_datasets = [
    "results/celegans_snps/rare_vs_common",
    "results/celegans_lethal/filtered",
]

model_template = "{genome}/{time_enc}/{clade_thres}/{dataset}/{model_size}/{loss_weight}/{seed}/{max_steps}/{use_aux_features}/{weight_conserved}/{flip_nonconserved}"

# default is first
hparams = {
    "dataset": [
        "multiz135way/135/128/64/True/defined.phastCons135way.percentile-75_0.05_0.001",
    ],

    "interval": [
        "128/64/True/defined.phastCons135way.percentile-75_0.05_0.001",
    ],
    
    "genome": [
        "ce11",
    ],

    "time_enc": [
        "fire_1",
    ],

    "clade_thres": [
        "0.2",
    ],

    "use_aux_features": [
        True,
    ],
    "loss_weight": [
        0.1,
    ],
    "weight_conserved": [
        True,
    ],
    "flip_nonconserved": [
        0.1,
    ],
}

default_d = {k: v[0] for k, v in hparams.items()}
hparam_models = [expand(model_template, **default_d, allow_missing=True)[0]]

# one ablation at a time
for k, v in hparams.items():
    for vv in v[1:]:
        new_d = default_d.copy()
        new_d[k] = vv
        hparam_models.append(expand(model_template, **new_d, allow_missing=True)[0])

models = sum(
    [
        expand(
            m,
            seed=[
                42,
            ],
            max_steps=[
                50_000,
            ],
            model_size=[
                "small",
                "medium",
            ],
        ) for m in hparam_models
    ],
    []
)
best_model = models[0]
#models = [best_model]

include: "rules/common.smk"
include: "rules/training.smk"
include: "rules/vep.smk"
include: "rules/logits.smk"
include: "rules/calibration.smk"
#include: "rules/embeddings.smk"
include: "rules/conservation.smk"

#models += ['ce11/phastCons135way', 'ce11/phyloP135way']

print(models)
print(vep_datasets)

rule all:
    input:
        #expand("results/checkpoints/{model}", model=models),
        expand("results/preds/llr/{dataset}/{model}.parquet", model=models, dataset=vep_datasets),